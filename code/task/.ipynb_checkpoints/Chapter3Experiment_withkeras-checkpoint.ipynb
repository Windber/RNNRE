{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 8\n",
    "output_dim = 2\n",
    "Tomita = 5\n",
    "thred = 0.05\n",
    "trpath = '/home/guo/code/test/RNNRE/data/tomita/T' + str(Tomita) + '_train'\n",
    "tepath_prefix = '/home/guo/code/test/RNNRE/data/tomita/T' + str(Tomita) + '_test'\n",
    "testn = 4\n",
    "inpalpha = {'s': 2, 'e': 3, '#': 3, '0': 0, '1': 1}\n",
    "labalpha = {'0': 0, '1': 1}\n",
    "ts = [32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(trpath, dtype={1: str}, index_col=None, header=None)\n",
    "train_lx = train_df.iloc[:, 0].values.tolist()\n",
    "train_ly = train_df.iloc[:, 1].values.tolist()\n",
    "train_x = [list(map(lambda x: inpalpha[x], i)) for i in train_lx]\n",
    "train_y = [list(map(lambda x: labalpha[x], i)) for i in train_ly]\n",
    "trx_np = np.array(train_x)\n",
    "try_np = np.array(train_y)\n",
    "trx = tf.one_hot(trx_np, 4)\n",
    "trl = tf.one_hot(try_np, 2)\n",
    "\n",
    "tex_l = list()\n",
    "tel_l = list()\n",
    "for i in range(testn):\n",
    "    test_df = pd.read_csv(tepath_prefix + str(i+1), dtype={1: str}, index_col=None, header=None)\n",
    "    test_lx = test_df.iloc[:, 0].values.tolist()\n",
    "    test_ly = test_df.iloc[:, 1].values.tolist()\n",
    "    test_x = [list(map(lambda x: inpalpha[x], i)) for i in test_lx]\n",
    "    test_y = [list(map(lambda x: labalpha[x], i)) for i in test_ly]\n",
    "    tex_np = np.array(test_x)\n",
    "    tey_np = np.array(test_y)\n",
    "    tex = tf.one_hot(tex_np, 4)\n",
    "    tel = tf.one_hot(tey_np, 2)\n",
    "    tex_l.append(tex)\n",
    "    tel_l.append(tel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.GRU(hidden_dim, input_shape=(32, 4), return_sequences=True),\n",
    "                         keras.layers.Dense(output_dim),\n",
    "                         keras.layers.Activation('softmax')])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200/200 [==============================] - 155s 777ms/step - loss: 0.6269 - acc: 0.6557\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 0.5634 - acc: 0.7219\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 141s 703ms/step - loss: 0.5472 - acc: 0.7301\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 139s 697ms/step - loss: 0.5407 - acc: 0.7308\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 140s 698ms/step - loss: 0.5292 - acc: 0.7375\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 141s 704ms/step - loss: 0.5084 - acc: 0.7402\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 140s 698ms/step - loss: 0.3978 - acc: 0.7718\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 138s 688ms/step - loss: 0.3235 - acc: 0.8073\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 140s 699ms/step - loss: 0.3070 - acc: 0.8143\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 140s 701ms/step - loss: 0.2947 - acc: 0.8216\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 138s 690ms/step - loss: 0.2682 - acc: 0.8396\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 138s 691ms/step - loss: 0.1446 - acc: 0.9349\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 141s 703ms/step - loss: 0.0136 - acc: 0.9990\n",
      "5/5 [==============================] - 6s 1s/step\n",
      "[0.0034046692308038473, 1.0]\n",
      "5/5 [==============================] - 7s 1s/step\n",
      "[0.0029379071202129126, 1.0]\n",
      "5/5 [==============================] - 9s 2s/step\n",
      "[0.0025200401432812214, 0.9999921917915344]\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(trx, trl, steps_per_epoch=200, epochs=1)\n",
    "while his.history['loss'][0] > thred:\n",
    "    his = model.fit(trx, trl, steps_per_epoch=200, epochs=1)\n",
    "\n",
    "\n",
    "for timestep, tex, tel in zip(ts, tex_l, tel_l):\n",
    "    emodel = keras.Sequential([keras.layers.GRU(hidden_dim, input_shape=(timestep, 4), return_sequences=True),\n",
    "                             keras.layers.Dense(output_dim),\n",
    "                             keras.layers.Activation('softmax')])\n",
    "    emodel.set_weights(model.get_weights())\n",
    "    emodel.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    a = emodel.evaluate(tex, tel, steps=5)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
